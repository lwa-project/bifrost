{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introductory-custody",
   "metadata": {},
   "source": "# Extending Bifrost\n\nWith the overview of Bifrost and how to build pipelines within the framework out of the way we can turn our attention to extending the core functionality of Bifrost. There are currently three options:\n\n1. **Pure Python implementation** within the low or high level APIs\n2. **Just-in-time compilation** via `bifrost.map` for GPU-accelerated custom operations\n3. **C/C++/CUDA module** with Python wrapper for maximum performance\n\nThis tutorial demonstrates each approach with working examples."
  },
  {
   "cell_type": "markdown",
   "id": "zfhzk36hqd",
   "source": "## Option 1: Pure Python Custom Block\n\nThe simplest way to extend Bifrost is to create a custom block using pure Python. This is ideal for operations that don't require GPU acceleration or where development speed is more important than performance.\n\nHere's an example of a custom `TransformBlock` that applies a simple scaling operation:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "0u85479288y",
   "source": "import bifrost as bf\nimport bifrost.pipeline as bfp\nfrom bifrost.blocks import CopyBlock\nimport numpy as np\n\nclass ScaleBlock(bfp.TransformBlock):\n    \"\"\"A custom block that scales input data by a constant factor.\n    \n    Args:\n        iring: Input ring\n        scale_factor: Multiplicative scale factor to apply\n    \"\"\"\n    def __init__(self, iring, scale_factor=1.0, *args, **kwargs):\n        super(ScaleBlock, self).__init__(iring, *args, **kwargs)\n        self.scale_factor = scale_factor\n    \n    def on_sequence(self, iseq):\n        \"\"\"Called when a new sequence starts. Return output header.\"\"\"\n        ihdr = iseq.header\n        # Copy input header and add our scale factor for documentation\n        ohdr = ihdr.copy()\n        ohdr['scale_applied'] = self.scale_factor\n        return ohdr\n    \n    def on_data(self, ispan, ospan):\n        \"\"\"Process each span of data.\"\"\"\n        idata = ispan.data\n        odata = ospan.data\n        # Apply the scaling operation\n        np.multiply(idata, self.scale_factor, out=odata)\n\n# Quick test of the custom block\nprint(\"ScaleBlock defined successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "m976q0omzb8",
   "source": "## Option 2: Using bifrost.map for GPU Acceleration\n\nFor GPU-accelerated custom operations, `bifrost.map` provides just-in-time compilation of custom CUDA code. This allows you to write CUDA kernels inline while Bifrost handles the compilation and execution.\n\nHere's an example that computes a custom transformation on the GPU:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "790feewzzob",
   "source": "# Example: Using bifrost.map for a custom GPU operation\n# This computes: output = sqrt(abs(input)) * sign(input)\n\nimport bifrost.map as bf_map\n\n# Define a custom transformation using CUDA code\n# The 'a' and 'b' variables are automatically mapped to input/output arrays\ncustom_kernel = \"\"\"\n// Compute signed square root: preserves sign while taking sqrt of magnitude\nb = sqrt(abs(a)) * (a >= 0 ? 1 : -1);\n\"\"\"\n\ndef apply_signed_sqrt(input_array, output_array):\n    \"\"\"Apply a signed square root transformation on GPU.\n    \n    Args:\n        input_array: Input bifrost ndarray on GPU\n        output_array: Output bifrost ndarray on GPU (same shape)\n    \"\"\"\n    bf_map.map(custom_kernel, {'a': input_array, 'b': output_array})\n\nprint(\"bifrost.map example defined!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "80f65yc5nw6",
   "source": "### Creating a MapBlock for Pipeline Integration\n\nTo use `bifrost.map` in a pipeline, you can wrap it in a block:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "tat3u1gwqi",
   "source": "class SignedSqrtBlock(bfp.TransformBlock):\n    \"\"\"GPU-accelerated signed square root using bifrost.map.\n    \n    Computes: output = sqrt(abs(input)) * sign(input)\n    \"\"\"\n    def __init__(self, iring, *args, **kwargs):\n        super(SignedSqrtBlock, self).__init__(iring, *args, **kwargs)\n        # Pre-define the kernel code for efficiency\n        self.kernel = \"b = sqrt(abs(a)) * (a >= 0 ? 1 : -1);\"\n    \n    def on_sequence(self, iseq):\n        return iseq.header\n    \n    def on_data(self, ispan, ospan):\n        bf_map.map(self.kernel, \n                   {'a': ispan.data, 'b': ospan.data})\n\nprint(\"SignedSqrtBlock defined successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dazpelbzlo",
   "source": "## Option 3: C/C++/CUDA Extension\n\nFor maximum performance or when wrapping existing libraries, you can add a native C extension to Bifrost. This involves several steps:\n\n### Step 1: Create the C Source File\n\nCreate a new source file in `src/` (e.g., `src/my_function.cpp`):\n\n```cpp\n#include <bifrost/my_function.h>\n#include <bifrost/array.h>\n\nBFstatus bfMyFunction(BFarray const* in, BFarray const* out, float scale) {\n    // Validate inputs\n    BF_ASSERT(in,  BF_STATUS_INVALID_POINTER);\n    BF_ASSERT(out, BF_STATUS_INVALID_POINTER);\n    \n    // Your implementation here\n    // Access data via in->data, out->data\n    // Check space via in->space (BF_SPACE_SYSTEM, BF_SPACE_CUDA, etc.)\n    \n    return BF_STATUS_SUCCESS;\n}\n```\n\n### Step 2: Create the Header File\n\nCreate `src/bifrost/my_function.h`:\n\n```c\n#ifndef BF_MY_FUNCTION_H_INCLUDE_GUARD_\n#define BF_MY_FUNCTION_H_INCLUDE_GUARD_\n\n#include <bifrost/common.h>\n#include <bifrost/array.h>\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n/*! \\p bfMyFunction applies a custom operation\n *  \\param in    Input array\n *  \\param out   Output array\n *  \\param scale Scale factor\n *  \\return BF_STATUS_SUCCESS on success\n */\nBFstatus bfMyFunction(BFarray const* in, BFarray const* out, float scale);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif // BF_MY_FUNCTION_H_INCLUDE_GUARD_\n```\n\n### Step 3: Update the Makefile\n\nAdd your object file to `LIBBIFROST_OBJS` in `src/Makefile`:\n\n```makefile\nLIBBIFROST_OBJS = ... my_function.o\n```\n\n### Step 4: Create the Python Wrapper\n\nAfter rebuilding (`make`), the ctypesgen tool automatically creates bindings in `bifrost.libbifrost_generated`. Create a high-level wrapper in `python/bifrost/my_function.py`:\n\n```python\nfrom bifrost.libbifrost import _bf, _check\nfrom bifrost.ndarray import ndarray\n\ndef my_function(src, dst, scale=1.0):\n    \"\"\"Apply custom operation.\n    \n    Args:\n        src: Input ndarray\n        dst: Output ndarray\n        scale: Scale factor\n    \"\"\"\n    _check(_bf.bfMyFunction(src.as_BFarray(), dst.as_BFarray(), scale))\n    return dst\n```",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "5rnjfiws70p",
   "source": "## Testing Your Extensions\n\nAlways test your custom blocks to ensure they work correctly:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "2qylm0u85wy",
   "source": "# Test the pure Python ScaleBlock\ndef test_scale_block():\n    \"\"\"Unit test for ScaleBlock.\"\"\"\n    import numpy.testing as npt\n    \n    # Create test data\n    input_data = np.array([1.0, 2.0, 3.0, 4.0], dtype=np.float32)\n    scale_factor = 2.5\n    expected = input_data * scale_factor\n    \n    # For a full test, you would run through a pipeline:\n    # with bfp.Pipeline() as pipeline:\n    #     data = bfp.blocks.read_numpy_block(pipeline, input_data)\n    #     scaled = ScaleBlock(data, scale_factor=scale_factor)\n    #     # ... validate output\n    \n    # Simple functional test\n    output_data = input_data * scale_factor\n    npt.assert_array_almost_equal(output_data, expected)\n    print(\"ScaleBlock test passed!\")\n\ntest_scale_block()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7ohcwn2mqlv",
   "source": "## Summary\n\n| Approach | Pros | Cons | Best For |\n|----------|------|------|----------|\n| **Pure Python** | Easy to write, debug | Slower for large data | Prototyping, simple operations |\n| **bifrost.map** | GPU-accelerated, flexible | Requires CUDA knowledge | Custom GPU kernels |\n| **C/C++ Extension** | Maximum performance | Most development effort | Production, libraries |\n\n### Plugin System (Coming Soon)\n\nWe are working on a plugin system that will make extending Bifrost easier by eliminating manual Makefile updates. See the preview at: https://github.com/lwa-project/bifrost/tree/plugin-wrapper/plugins",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}